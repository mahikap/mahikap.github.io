---
layout: page
title: Projects
subtitle:
desc: 
permalink: /projects/
---

<div class="lead pretty-links" style="font-weight:800; font-style:italic">The Present</div>
<hr style="border:1.5px solid #7771b064">

<div class="projects">
  <div class="grid no-gutters">

    <div class="unit half">
      <div class="project">
        <h4 class="project-title">Under Construction</h4>
      </div>
    </div>
  </div>

<!-- <div class="projects">
  <div class="grid no-gutters">

    <div class="unit half">
      <div class="project">
        <h4 class="project-title">Conversational Access to User <br>Interfaces</h4>
        <p>
          People with visual impairments use screen readers to navigate graphical interfaces, i.e. laptops, mobiles. But, screen readers
          are inherantly readers, they provide one-way linear stream of information. What if screen readers were intelligent? What 
          if they could present information in an efficient and intentional manner? I investigate voice-based access to screens, using design
          research and prototyping methodologies.
        </p>
        <p style="font-size:16px;font-style: italic; font-weight: 800;">Supervised By: <br>Dr. Shiri Azenkot, Dr. Qian Yang</p>
      </div>
    </div>

    <div class="unit half">
      <div class="project">
        <h4 class="project-title">Perceptions and New Wave of <br>Voice Assistants</h4>
        <p>
          Personified voice assistants, such as Alexa and Siri, cultivate interesting power (im)balances 
          between themselves and people with disabilities. To some, these agents may contribute to confidence and self-efficacy, 
          while to others, it may be disheartening to rely on a black-box system. I study the perceptions around voice assistants, 
          and bridge these mental models to newer designs of voice assistants that "empower" users with disabilities. 
        </p>
        <p style="font-size:16px;font-style: italic; font-weight: 800;">Supervised By: <br>Dr. Shiri Azenkot</p>
      </div>
    </div>

    <div class="unit half">
      <div class="project">
        <h4 class="project-title">Microagressive Experiences of People with Disabilities</h4>
        <p>
          Social media is a place where marginalized communities are susceptible to subtle forms of discrimination and 
          harm; perpetuating experiences of feeling unwelcomed. Through this study, we aim to understand how people with disabilities
          experience microaggressions (e.g., ableism, patronization) on social media platforms, and how their social media experience is shaped through such disability-specific microaggressions.
        </p>
        <p style="font-size:16px;font-style: italic; font-weight: 800;">Supervised By: 
        <br>Dr. Aditya Vashistha, Dr. Megh Marathe
        </p>
      </div>
    </div>

    <div class="unit half">
      <div class="project">
        <br>
        <h4 class="project-title">Self-Presentation in Social <br>Virtual Reality</h4>
        <p>
          (In brainstorming phase)
        </p>
      </div>
    </div>

  </div> -->

  <br>
  <div class="lead pretty-links" style="font-weight:800; font-style:italic">The Past</div>
  <hr style="border:1.5px solid #7771b064">
  
  
  <div class="grid no-gutters">

    <div class="unit half">
      <div class="project">
        <h4 class="project-title">Ableism on Social Media</h4>
        <p>
          With growing disability advocacy on social media, disabled people are susceptible to discrimination, harassment, and 
          harm, especially implicit and subtle forms of harm. We studied how people with disabilities experience microaggressions (e.g., patronization, invalidation) on social media platforms, 
          shedding light into technology-mediated ableism. <br>
          <a target="_blank" style="font-size:15px" href="https://doi.org/10.1145/3517428.3544801">[ASSETS '22]</a>
        </p>
        <p style="font-size:16px;font-style: italic; font-weight: 800;">Lead by: 
          <br>Sharon Heung, Cornell Tech
        <p style="font-size:16px;font-style: italic; font-weight: 800;">Supervised by: 
          <br>Dr. Aditya Vashistha, Cornell University <br> Dr. Megh Marathe, Michigan State
        </p>
      </div>
    </div>

    <div class="unit half">
      <div class="project">
        <h4 class="project-title">Video Accessibility for Blind People</h4>
        <p>
          We explored ways to improve contextual and 360Â° video accessibility for blind and low vision
          viewers with immersion and engagement as key pillars, facets not provided by current-day audio descriptions (AD). 
          We conducted design workshops and synthesized key accessibility guidelines through 
          discussions with professional describers, voice actors, sound designers, and AD users. 
          <a target="_blank" style="font-size:15px" href="https://dl.acm.org/doi/abs/10.1145/3597638.3608381">
            [ASSETS '23</a>, <a target="_blank" style="font-size:15px" href="https://dl.acm.org/doi/10.1145/3613904.3642238">
              CHI '24]</a>
        </p>
        <p style="font-size:16px;font-style: italic; font-weight: 800;">Lead by: 
          <br>Lucy Jiang, University of Washington</p>
        <p style="font-size:16px;font-style: italic; font-weight: 800;">Supervised by: 
          <br>Dr. Abigail Stangl, Georgia Tech <br> Dr. Shiri Azenkot, Cornell Tech<br></p>
      </div>
    </div>

    <div class="unit half">
      <div class="project">
        <h4 class="project-title">Hands-Free Virtual Reality</h4>
        <p>
          People with neuromotor impairments have difficulty operating virtual reality controllers, 
          especially if they use a wheelchair. They may lower fine motor ability, or have spasticity in their muscles. 
          Working with a physiotherapist, we developed the functionality of using head orientation to onboard the Oculus and 
          navigate menus in virtual reality. 
          <a target="_blank" style="font-size:15px" href="https://docs.google.com/presentation/d/1Rga63e_WMMATJSvTINodZswjjyuKhqOPHKhheyX8tvg/edit?usp=sharing">
            [Presentation to XR Access '21]</a>
        </p>
        <p style="font-size:16px;font-style: italic; font-weight: 800;">Supervised by: 
          <br>Dr. Steven Feiner, Columbia University <br><br></p>
      </div>
    </div>

    <div class="unit half"></div>
      <div class="project">
        <h4 class="project-title">Accessible Mid-Air Haptics Design</h4>
        <p>
          <a href="https://www.ultraleap.com/haptics/">Mid-air haptic interfaces </a>enable rich 3D interactions but are inaccessible
          to users with disabilities. We designed an interactive simulation of a contactless elevator control panel 
          with mid-air touch feedback and accessibility considerations. Despite being fully contactless, 
          the controls are tactile, they emit braille, and closely resemble the mental model of ordinary elevator buttons. 
          <a target="_blank" style="font-size:15px" href="https://dl.acm.org/doi/10.1145/3411763.3451574">[CHI EA '21]</a>
        </p>
        <p style="font-size:16px;font-style: italic; font-weight: 800;">Collaborators: <br>Tanay Singhal, University of Waterloo</p>
      </div>
    </div>


  </div>

  

  <!-- <div class="grid no-gutters">

    <div class="unit one-third">
      <div class="project">
        <h4 class="project-title"><a href="sample-project/">Project 4</a></h4>
        <p>Inpune adsueta ac portasque, esse bella satis; meum arserunt coepit. Anguesque caeleste, dixit: pars nemus igne sedes nigrantis dea omnia.</p>
      </div>
    </div>


    <div class="unit one-third">
      <div class="project">
        <h4 class="project-title"><a href="sample-project/">Project 5</a></h4>
        <p>Laeva clamat qui Perseus erit, discrimine ramos illa <a href="sample-project/">restabat</a>: bracchia, templa, ab spectans. Monte contigit Rhodosque manus mille est omnia eiusdem nondum: qui Modo.</p>
      </div>
    </div>
  </div>grid -->
</div>
